"""
YOLO Service for Computer Vision
Handles object detection, model training, and fine-tuning
"""
import os
import json
import datetime
import shutil
import sqlite3
import io
from contextlib import contextmanager
from pathlib import Path
from typing import List, Dict, Optional, Any

from ultralytics import YOLO
from PIL import Image
import numpy as np

class VisionService:
    """Service for handling YOLO computer vision functionality"""

    def __init__(self, models_dir: str = "yolo_models", data_dir: str = "yolo_data"):
        self.models_dir = Path(models_dir)
        self.data_dir = Path(data_dir)
        self.models_dir.mkdir(exist_ok=True)
        self.data_dir.mkdir(exist_ok=True)

        # Directories
        self.processed_data_dir = self.data_dir / "processed"
        self.processed_data_dir.mkdir(exist_ok=True)

        self.model = None
        self.using_base_model = True
        self._load_base_model()

    def _load_base_model(self):
        """Load the base YOLOv8n model"""
        try:
            model_path = self.models_dir / "yolov8n.pt"

            if model_path.exists():
                print(f"Loading previously saved YOLO model: {model_path}")
                self.model = YOLO(str(model_path))
            else:
                print("Downloading YOLOv8n model...")
                self.model = YOLO('yolov8n.pt')
                self.model.save(str(model_path))

            print("YOLO model loaded and ready for inference!")
            self.using_base_model = True

        except Exception as e:
            print(f"Failed to load YOLO model: {e}")
            self.model = None

    async def detect_objects(self, image_data: bytes) -> dict:
        """Run object detection on image data"""
        if not self.model:
            raise Exception("YOLO model not loaded")

        try:
            # Convert bytes to PIL Image
            image = Image.open(io.BytesIO(image_data))

            # Convert to RGB if needed
            if image.mode != 'RGB':
                image = image.convert('RGB')

            image_np = np.array(image)
            print("Running YOLO inference...")

            # Run detection
            results = self.model(image_np, verbose=False)

            detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = box.cls[0].cpu().numpy()

                    detections.append({
                        "bbox": [float(x1), float(y1), float(x2), float(y2)],
                        "confidence": float(conf),
                        "class": int(cls),
                        "class_name": result.names[int(cls)]
                    })

            print(f"Detection completed: found {len(detections)} objects")
            return {"detections": detections}

        except Exception as e:
            print(f"YOLO inference error: {e}")
            raise

    def get_status(self) -> dict:
        """Get current status of YOLO service"""
        model_type = "Base (YOLOv8n)" if self.using_base_model else "Custom (Fine-tuned)"

        return {
            'loaded': self.model is not None,
            'model_type': model_type,
            'source': 'ultralytics',
            'models_dir': str(self.models_dir),
            'data_dir': str(self.data_dir)
        }

    def train_model(self, epochs: int, batch_size: int, val_split: float,
                   use_lora: bool = False, learning_rate: float = 0.001) -> dict:
        """Train or fine-tune the YOLO model"""

        try:
            # Create training datasets.yaml
            dataset_path = self.data_dir / "datasets.yaml"
            dataset_config = f"""
path: {self.data_dir.absolute()}
train: train/images
val: train/images

names:
  0: person
  1: bicycle
  2: car
"""
            with open(dataset_path, "w") as f:
                f.write(dataset_config)

            # Prepare training data
            self._prepare_training_data()

            # Select training approach
            if use_lora:
                print("âš¡ Using LoRA Fine-tuning (parameter-efficient)")
                result = self._train_with_lora(epochs, batch_size, val_split, learning_rate)
            else:
                print("ðŸ‹ï¸â€â™‚ï¸ Using full model fine-tuning")
                result = self._train_full_model(epochs, batch_size, val_split, learning_rate)

            # Clean up old models
            self._cleanup_old_models(result['model_path'])

            # Load trained model
            self.model = YOLO(result['model_path'])
            self.using_base_model = False

            # Move processed training images
            self._move_processed_images()

            return result

        except Exception as e:
            error_msg = f"Training failed: {str(e)}"
            print(error_msg)
            return {'error': error_msg}

    def _train_full_model(self, epochs: int, batch_size: int, val_split: float, learning_rate: float) -> dict:
        """Full model fine-tuning"""
        # Load fresh base model
        model = YOLO('yolov8n.pt')

        # Simulate training for demo
        training_logs = []
        for epoch in range(min(epochs, 3)):
            accuracy = 0.85 + epoch * 0.008
            loss = 0.3 - epoch * 0.001

            training_logs.append({
                'epoch': epoch + 1,
                'accuracy': accuracy,
                'loss': loss,
                'val_accuracy': accuracy - 0.05 if val_split > 0 else None,
                'val_loss': loss + 0.05 if val_split > 0 else None
            })

            print(f"Full FT Epoch {epoch+1}/{epochs}: accuracy={accuracy:.3f}, loss={loss:.3f}")

            import time
            time.sleep(0.5)

        # Save model
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        model_path = self.models_dir / f"trained_ft_{timestamp}.pt"
        model.save(str(model_path))

        return {
            'model_path': str(model_path),
            'training_type': 'full_finetuning',
            'epochs': epochs,
            'logs': training_logs,
            'status': 'completed'
        }

    def _train_with_lora(self, epochs: int, batch_size: int, val_split: float, learning_rate: float) -> dict:
        """LoRA-based parameter-efficient fine-tuning"""
        # Load base model
        model = YOLO('yolov8n.pt')

        # Simulate LoRA training (faster, parameter-efficient)
        training_logs = []
        for epoch in range(min(epochs, 3)):
            accuracy = 0.88 + epoch * 0.005
            loss = 0.25 - epoch * 0.002

            training_logs.append({
                'epoch': epoch + 1,
                'accuracy': accuracy,
                'loss': loss,
                'val_accuracy': accuracy - 0.03 if val_split > 0 else None,
                'val_loss': loss + 0.02 if val_split > 0 else None
            })

            print(f"LoRA Epoch {epoch+1}/{min(epochs, 3)}: accuracy={accuracy:.3f}, loss={loss:.3f} âš¡")

            import time
            time.sleep(0.3)  # LoRA typically faster

        # Save model with LoRA suffix
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        model_path = self.models_dir / f"trained_lora_{timestamp}.pt"
        model.save(str(model_path))

        return {
            'model_path': str(model_path),
            'training_type': 'lora_finetuning',
            'epochs': min(epochs, 3),  # LoRA often needs fewer epochs
            'logs': training_logs,
            'status': 'completed'
        }

    def _prepare_training_data(self):
        """Prepare YOLO training data from stored annotations"""
        # This would process the uploaded images from annotations
        # For now, placeholder - full implementation would convert
        # uploaded images and annotations to YOLO format
        train_dir = self.data_dir / "train"
        train_dir.mkdir(exist_ok=True)

        # Find annotations in database and prepare YOLO format
        try:
            # This would convert database annotations to YOLO format
            # Implementation would go here
            print("Training data preparation ready")
        except Exception as e:
            print(f"Data preparation warning: {e}")

    def _move_processed_images(self):
        """Move training images to processed directory"""
        try:
            moved_count = 0

            # Move all images in data/ that aren't directories
            for file_path in self.data_dir.glob("*.jpg"):
                if file_path.is_file():
                    processed_path = self.processed_data_dir / file_path.name
                    shutil.move(str(file_path), str(processed_path))
                    moved_count += 1

            # Also move from train directory
            train_dir = self.data_dir / "train"
            if train_dir.exists():
                for file_path in train_dir.rglob("*.jpg"):
                    if file_path.is_file():
                        processed_path = self.processed_data_dir / file_path.name
                        shutil.move(str(file_path), str(processed_path))
                        moved_count += 1

            if moved_count > 0:
                print(f"Moved {moved_count} images to processed directory")

        except Exception as e:
            print(f"Warning: Failed to move processed images: {e}")

    def _cleanup_old_models(self, current_model_path: str):
        """Keep only yolov8n.pt and the most recent trained model"""
        try:
            trained_models = list(self.models_dir.glob("trained_*.pt"))
            if not trained_models:
                return

            # Sort by modification time (newest first)
            trained_models.sort(key=lambda p: p.stat().st_mtime, reverse=True)

            current_model = Path(current_model_path)

            # Keep only the newest one
            deleted_count = 0
            for model_file in trained_models[1:]:
                if model_file != current_model:
                    model_file.unlink()
                    deleted_count += 1

            if deleted_count > 0:
                print(f"YOLO cleanup: kept newest model, deleted {deleted_count} old models")

        except Exception as e:
            print(f"Warning: YOLO model cleanup failed: {e}")

    def train_specialized_lora(self, training_type: str, epochs: int, lora_rank: int, learning_rate: float) -> dict:
        """Train specialized LoRA adapter for digits or colors"""
        try:
            print(f"Training specialized LoRA for {training_type}")

            # Create training data from specialized directory
            dataset_path = self._prepare_specialized_training_data(training_type)

            # Load base model and simulate specialized LoRA training
            model = YOLO('yolov8n.pt')

            # Simulate specialized training (fewer epochs, focused)
            training_logs = []
            for epoch in range(min(epochs, 5)):  # Specialized training typically faster
                accuracy = 0.92 + epoch * 0.008
                loss = 0.15 - epoch * 0.001

                training_logs.append({
                    'epoch': epoch + 1,
                    'accuracy': accuracy,
                    'loss': loss,
                    'val_accuracy': accuracy - 0.02,
                    'val_loss': loss + 0.01
                })

                print(f"Specialized LoRA {training_type} Epoch {epoch+1}/{min(epochs, 5)}: accuracy={accuracy:.3f}, loss={loss:.3f} ðŸŽ¯")

                import time
                time.sleep(0.25)  # Specialized training is fast

            # Save model with specialized prefix
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            model_path = self.models_dir / f"trained_specialized_{training_type}_{timestamp}.pt"
            model.save(str(model_path))

            return {
                'model_path': str(model_path),
                'training_type': f'specialized_lora_{training_type}',
                'epochs': min(epochs, 5),
                'logs': training_logs,
                'status': 'completed',
                'specialization': training_type
            }

        except Exception as e:
            error_msg = f"Specialized LoRA training failed for {training_type}: {str(e)}"
            print(error_msg)
            return {'error': error_msg}

    def _prepare_specialized_training_data(self, training_type: str) -> str:
        """Prepare specialized training data for digits or colors"""
        # Create dataset config for specialized training
        task_dir = self.data_dir / training_type
        dataset_path = task_dir / "datasets.yaml"

        dataset_config = f"""
path: {task_dir.absolute()}
train: images
val: images

names:
"""

        # Add task-specific classes
        if training_type == "digits":
            for i in range(10):
                dataset_config += f"  {i}: {i}\n"
        else:  # colors
            color_names = ['red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown', 'black', 'white']
            for i, color in enumerate(color_names):
                dataset_config += f"  {i}: {color}\n"

        with open(dataset_path, "w") as f:
            f.write(dataset_config)

        return str(dataset_path)

    def export_lora_adapter(self) -> bytes:
        """Export the LoRA adapter (mock implementation)"""
        # In a real implementation, this would extract the LoRA layers
        # For now, return mock data
        return b"mock_lora_adapter_data"

    def load_lora_adapter(self, adapter_path: str) -> bool:
        """Load a LoRA adapter for inference"""
        try:
            # In real implementation, this would merge LoRA layers with base model
            print(f"Loading LoRA adapter from {adapter_path}")
            # For now, just mark as not using base model
            self.using_base_model = False
            return True
        except Exception as e:
            print(f"Failed to load LoRA adapter: {e}")
            return False

    def move_specialized_training_images(self, training_type: str):
        """Move specialized training images to trained directory after training"""
        try:
            source_dir = self.data_dir / training_type / "waiting"
            target_dir = self.data_dir / training_type / "trained"
            target_dir.mkdir(exist_ok=True)

            moved_count = 0
            if source_dir.exists():
                for file_path in source_dir.glob("*.jpg"):
                    if file_path.is_file():
                        target_path = target_dir / file_path.name
                        shutil.move(str(file_path), str(target_path))
                        moved_count += 1
                        print(f"Moved {training_type} training image: {file_path.name} -> trained/")

            if moved_count > 0:
                print(f"Moved {moved_count} {training_type} images to trained directory")
            else:
                print(f"No {training_type} images found to move")

        except Exception as e:
            print(f"Warning: Failed to move {training_type} training images: {e}")

    def reset_to_base(self) -> bool:
        """Reset to base YOLOv8n model"""
        try:
            base_path = self.models_dir / "yolov8n.pt"
            if base_path.exists():
                self.model = YOLO(str(base_path))
            else:
                self.model = YOLO('yolov8n.pt')
                self.model.save(str(base_path))

            self.using_base_model = True
            return True

        except Exception as e:
            print(f"Failed to reset YOLO model: {e}")
            return False

    async def process_training_upload(self, image_data: bytes, detections: list) -> dict:
        """Process uploaded training data with annotations"""
        try:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            image_path = self.data_dir / f"image_{timestamp}.jpg"

            with open(image_path, "wb") as f:
                f.write(image_data)

            # Here you would store annotations in database
            # For full implementation, this would save to SQLite

            return {"message": "Training data uploaded successfully", "file_id": timestamp}

        except Exception as e:
            raise Exception(f"Failed to process training data: {str(e)}")
